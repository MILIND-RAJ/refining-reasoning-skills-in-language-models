{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Connect to drive"
      ],
      "metadata": {
        "id": "tSpnunvLy74H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J_7tpbVy1L_",
        "outputId": "1388b00f-6cf9-4723-8dc4-5b44bd6bac18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iXNMUd_djsM"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "api_key = ''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=api_key,\n",
        ")"
      ],
      "metadata": {
        "id": "MasncoXhdxu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "f = open('/content/drive/MyDrive/CSCI544/Project/dataset/dataset/multiarith.json')\n",
        "data = json.load(f)"
      ],
      "metadata": {
        "id": "lkSIhErS7Eio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "for i in range(int(len(data['data'])*0.7)):\n",
        "  d = {}\n",
        "  d['prompt'] = data['data'][i]['question']\n",
        "  chat_completion = client.chat.completions.create(\n",
        "  messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": data['data'][i]['question']+\". Think step by step.\",\n",
        "        }\n",
        "    ], model=\"gpt-4\",)\n",
        "  d[\"completion\"] = chat_completion.choices[0].message.content + \"--> \" + data['data'][i]['answer'] + \" END\"\n",
        "  training_data.append(d)"
      ],
      "metadata": {
        "id": "D_Y635I0khSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_file_name = \"training_data.jsonl\"\n",
        "\n",
        "def prepare_data(dictionary_data, final_file_name):\n",
        "    with open(final_file_name, 'w') as outfile:\n",
        "        for entry in dictionary_data:\n",
        "        \tjson.dump(entry, outfile)\n",
        "        \toutfile.write('\\n')\n",
        "\n",
        "prepare_data(training_data, \"training_data.jsonl\")"
      ],
      "metadata": {
        "id": "I7N8Knyoktyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_file_id = client.files.create(\n",
        "  file=open(training_file_name, \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "print(f\"Training File ID: {training_file_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Boz96aSMsJBk",
        "outputId": "0b6beddf-13d1-4688-eb5c-cc807b878ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training File ID: FileObject(id='file-kcjw9Z2AP6eBtVjwxRiNmk47', bytes=200373, created_at=1711413079, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file=training_file_id.id,\n",
        "  model=\"babbage-002\",\n",
        "  hyperparameters={\n",
        "    \"n_epochs\": 5\n",
        "  }\n",
        ")\n",
        "job_id = response.id\n",
        "status = response.status\n",
        "\n",
        "print(f'Fine-tunning model with jobID: {job_id}.')\n",
        "print(f\"Training Response: {response}\")\n",
        "print(f\"Training Status: {status}\")"
      ],
      "metadata": {
        "id": "hFL1AFg4srLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = client.fine_tuning.jobs.list()\n",
        "fine_tuned_model = result.data[0].fine_tuned_model\n",
        "result.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7160JoXtLb2",
        "outputId": "9e8f210f-db35-443e-a046-b9b3071b3902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-sOYHdev7H9oPtXPvnC2b03jE', created_at=1711413105, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=30, batch_size=8, learning_rate_multiplier=2), model='babbage-002', object='fine_tuning.job', organization_id='org-JrmVss1Zj1qhFSpn2QGWUSiR', result_files=[], status='cancelled', trained_tokens=None, training_file='file-kcjw9Z2AP6eBtVjwxRiNmk47', validation_file=None, user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "for i in range(int(len(data['data'])*0.7), len(data['data'])):\n",
        "\n",
        "  new_prompt = data['data'][i]['question']\n",
        "  answer = client.completions.create(\n",
        "    model=fine_tuned_model,\n",
        "    prompt=new_prompt,\n",
        "    max_tokens = 150\n",
        "  )\n",
        "  try:\n",
        "    pred = int(answer.choices[0].text.split(\"-->\")[1].split(\"END\")[0].strip())\n",
        "  except:\n",
        "    pred = -9999\n",
        "    pass\n",
        "  ans = data['data'][i]['answer']\n",
        "  if '.' in data['data'][i]['answer']:\n",
        "    pred=float(pred)\n",
        "    ans = float(ans)\n",
        "  else:\n",
        "    ans = int(ans)\n",
        "  if pred == ans:\n",
        "    correct_predictions+= 1\n",
        "\n",
        "total_data_points = len(data['data']) - int(len(data['data'])*0.7)\n",
        "print(\"Accuracy = \",(correct_predictions/total_data_points)*100, \"%\")"
      ],
      "metadata": {
        "id": "uf6EuTyptWQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W6gJJa9b5shZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}